{"timestamp":"2025-07-17T20:45:33.735091","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-07-17T20:45:33.745326","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag2.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-17T20:46:04.155723","level":"error","event":"Process timed out, PID: 198","logger":"airflow.utils.timeout.TimeoutPosix"}
{"timestamp":"2025-07-17T20:46:04.167881Z","level":"error","event":"Exception ignored in: <function _collection_gced at 0x7fdc84186200>","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-17T20:46:04.168309Z","level":"error","event":"Traceback (most recent call last):","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-17T20:46:04.168620Z","level":"error","event":"  File \"/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/event/registry.py\", line 53, in _collection_gced","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-17T20:46:04.168911Z","level":"error","event":"    def _collection_gced(ref):","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-17T20:46:04.169230Z","level":"error","event":"  File \"/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/timeout.py\", line 69, in handle_timeout","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-17T20:46:04.169553Z","level":"error","event":"    raise AirflowTaskTimeout(self.error_message)","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-17T20:46:04.170140Z","level":"error","event":"airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/dag2.py after 30.0s.","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-17T20:46:04.171327Z","level":"error","event":"Please take a look at these docs to improve your DAG import time:","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-17T20:46:04.173938Z","level":"error","event":"* https://airflow.apache.org/docs/apache-airflow/3.0.2/best-practices.html#top-level-python-code","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-17T20:46:04.174531Z","level":"error","event":"* https://airflow.apache.org/docs/apache-airflow/3.0.2/best-practices.html#reducing-dag-complexity, PID: 198","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-17T20:46:04.681233","level":"info","event":"Validating data quality for table: sale_transactions","logger":"unusual_prefix_b32ce7d530ba84fdd1796e135f31aa77492b4d52_dag2"}
{"timestamp":"2025-07-17T20:46:05.200583","level":"info","event":"Connection Retrieved 'postgres_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-07-17T20:46:07.635987","level":"warning","event":"/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/common/sql/hooks/sql.py:482: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n  return psql.read_sql(sql, con=conn, params=parameters, **kwargs)\n","logger":"py.warnings"}
{"timestamp":"2025-07-17T20:46:27.743930","level":"error","event":"Error validating data quality for table: sale_transactions. Error: cursor already closed","logger":"unusual_prefix_b32ce7d530ba84fdd1796e135f31aa77492b4d52_dag2"}
{"timestamp":"2025-07-17T20:46:27.950177","level":"info","event":"Done. Returned value was: False","logger":"airflow.task.operators.airflow.providers.standard.decorators.python._PythonDecoratedOperator"}
{"timestamp":"2025-07-17T20:46:27.951179","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('01981a22-898e-70a6-a98f-f5d75da5ef93'), task_id='validate_data_quality_sale_transactions', dag_id='postgres_gcs_validation_dag', run_id='manual__2025-07-17T20:45:27.776463+00:00', try_number=1, map_index=-1, hostname='35c045f9d0d4', context_carrier={}, task=<Task(_PythonDecoratedOperator): validate_data_quality_sale_transactions>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=3, start_date=datetime.datetime(2025, 7, 17, 20, 45, 29, 859125, tzinfo=TzInfo(UTC)), end_date=None, state=<TaskInstanceState.RUNNING: 'running'>, is_mapped=False, rendered_map_index=None)","logger":"task"}

{"timestamp":"2025-07-17T20:45:35.473812","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-07-17T20:45:35.493824","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag2.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-17T20:46:06.199441","level":"error","event":"Process timed out, PID: 200","logger":"airflow.utils.timeout.TimeoutPosix"}
{"timestamp":"2025-07-17T20:46:06.209044Z","level":"error","event":"Exception ignored in: <function _collection_gced at 0x7fdc84186200>","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-17T20:46:06.209559Z","level":"error","event":"Traceback (most recent call last):","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-17T20:46:06.209811Z","level":"error","event":"  File \"/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/event/registry.py\", line 53, in _collection_gced","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-17T20:46:06.210097Z","level":"error","event":"    def _collection_gced(ref):","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-17T20:46:06.210464Z","level":"error","event":"  File \"/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/timeout.py\", line 69, in handle_timeout","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-17T20:46:06.211067Z","level":"error","event":"    raise AirflowTaskTimeout(self.error_message)","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-17T20:46:06.212046Z","level":"error","event":"airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/dag2.py after 30.0s.","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-17T20:46:06.212629Z","level":"error","event":"Please take a look at these docs to improve your DAG import time:","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-17T20:46:06.212928Z","level":"error","event":"* https://airflow.apache.org/docs/apache-airflow/3.0.2/best-practices.html#top-level-python-code","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-17T20:46:06.213295Z","level":"error","event":"* https://airflow.apache.org/docs/apache-airflow/3.0.2/best-practices.html#reducing-dag-complexity, PID: 200","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-17T20:46:06.513462","level":"info","event":"Validating data quality for table: sales_managers","logger":"unusual_prefix_b32ce7d530ba84fdd1796e135f31aa77492b4d52_dag2"}
{"timestamp":"2025-07-17T20:46:06.634543","level":"info","event":"Connection Retrieved 'postgres_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-07-17T20:46:07.637892","level":"warning","event":"/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/common/sql/hooks/sql.py:482: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n  return psql.read_sql(sql, con=conn, params=parameters, **kwargs)\n","logger":"py.warnings"}
{"timestamp":"2025-07-17T20:46:07.991130","level":"error","event":"Error validating data quality for table: sales_managers. Error: cursor already closed","logger":"unusual_prefix_b32ce7d530ba84fdd1796e135f31aa77492b4d52_dag2"}
{"timestamp":"2025-07-17T20:46:08.003550","level":"info","event":"Done. Returned value was: False","logger":"airflow.task.operators.airflow.providers.standard.decorators.python._PythonDecoratedOperator"}
{"timestamp":"2025-07-17T20:46:08.018688","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('01981a22-8996-7605-9efd-610d39a826fa'), task_id='validate_data_quality_sales_managers', dag_id='postgres_gcs_validation_dag', run_id='manual__2025-07-17T20:45:27.776463+00:00', try_number=1, map_index=-1, hostname='35c045f9d0d4', context_carrier={}, task=<Task(_PythonDecoratedOperator): validate_data_quality_sales_managers>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=3, start_date=datetime.datetime(2025, 7, 17, 20, 45, 29, 916305, tzinfo=TzInfo(UTC)), end_date=None, state=<TaskInstanceState.RUNNING: 'running'>, is_mapped=False, rendered_map_index=None)","logger":"task"}
